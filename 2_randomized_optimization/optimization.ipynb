{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split,\\\n",
    "      LearningCurveDisplay, learning_curve\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "import mlrose_hiive as mlrose\n",
    "from mlrose_hiive import MaxKColorGenerator, QueensGenerator, FlipFlopGenerator,\\\n",
    "      TSPGenerator, KnapsackGenerator, ContinuousPeaksGenerator\n",
    "from mlrose_hiive import SARunner, GARunner, NNGSRunner, MIMICRunner, RHCRunner\n",
    "# from mlrose_hiive import SKMLPRunner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine = os.path.join('data','wine', 'winequality-red.csv')\n",
    "white_wine = os.path.join('data','wine', 'winequality-white.csv')\n",
    "turbine = os.path.join('data','turbine','gt_2011.csv')\n",
    "mushrooms = os.path.join('data','mushroom','secondary_data.csv')\n",
    "\n",
    "# encoders to use\n",
    "scale = StandardScaler()\n",
    "s_split = ShuffleSplit()\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (\n",
    "        ohe, \n",
    "        [\n",
    "        'cap-shape', 'cap-surface', 'cap-color',\n",
    "       'does-bruise-or-bleed', 'gill-attachment','gill-spacing', 'gill-color', \n",
    "       'stem-root', 'stem-surface', 'stem-color','veil-type', 'veil-color',\n",
    "        'has-ring', 'ring-type', 'spore-print-color','habitat', 'season'\n",
    "        ]\n",
    "        ),\n",
    "    remainder='passthrough'\n",
    "    )\n",
    "\n",
    "shroom_df = pd.read_csv(mushrooms,sep=';').sample(frac=1).reset_index(drop=True)\n",
    "x = shroom_df.iloc[:,1:].copy()\n",
    "x_shroom = pd.DataFrame(transformer.fit_transform(x), \n",
    "                columns=transformer.get_feature_names_out())\n",
    "y = shroom_df.iloc[:,0].copy()\n",
    "y_shroom = (y == 'p')\n",
    "\n",
    "\n",
    "# reduce the number of training examples\n",
    "x_shroom = x_shroom[:7000]\n",
    "y_shroom =  y_shroom[:7000]\n",
    "\n",
    "x_shroom_train, x_shroom_test, y_shroom_train, y_shroom_test = train_test_split(\n",
    "    x_shroom, y_shroom, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_df = pd.read_csv(white_wine, sep=';')\n",
    "red_df = pd.read_csv(red_wine, sep=';')\n",
    "white_df['type'] = 0\n",
    "red_df['type'] = 1\n",
    "wine_df = pd.concat([white_df,red_df])\n",
    "wine_df = wine_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# set x and y values\n",
    "# remove 'quality' and 'type' column from x array\n",
    "x_wine = wine_df.iloc[:,:-2].copy()\n",
    "# scale x vals\n",
    "x_wine.values[:,:] = scale.fit_transform(x_wine)\n",
    "# set y array equal to 'type' column \n",
    "y_wine = wine_df.iloc[:,-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0486618 , 0.04854369, 0.04926108, 0.06947891, 0.04580153,\n",
       "        0.06451613, 0.03608247, 0.0302267 , 0.05472637, 0.08312958],\n",
       "       [0.0486618 , 0.04854369, 0.04926108, 0.06947891, 0.04580153,\n",
       "        0.06451613, 0.03608247, 0.0302267 , 0.05472637, 0.08312958],\n",
       "       [0.0486618 , 0.04854369, 0.04926108, 0.06947891, 0.04580153,\n",
       "        0.06451613, 0.03608247, 0.0302267 , 0.05472637, 0.08312958]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = np.linspace(0.1, 1.0, 5)\n",
    "cv = ShuffleSplit()\n",
    "\n",
    "nn = mlrose.NeuralNetwork(hidden_nodes = [100],\n",
    "                                activation = 'relu',\n",
    "                                algorithm = 'simulated_annealing',\n",
    "                                max_iters = 10,\n",
    "                                bias = True,\n",
    "                                is_classifier = True,\n",
    "                                learning_rate = 0.001,\n",
    "                                early_stopping = True,\n",
    "                                clip_max = 5,\n",
    "                                max_attempts =100,\n",
    "                                curve=False,\n",
    "                                random_state = 123456)\n",
    "\n",
    "train_sizes_sa, train_scores_sa, test_scores_sa, fit_times_sa, score_times_sa = learning_curve(\n",
    "    nn, X=x_shroom.to_numpy(), y=y_shroom.to_numpy(), cv=cv,\n",
    "    train_sizes=[0.3, 0.6, 0.9], return_times=True, random_state=123456,\n",
    "    # scoring='precision',\n",
    ")\n",
    "\n",
    "test_scores_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "train_size = np.linspace(0.1, 1.0, 5)\n",
    "cv = ShuffleSplit()\n",
    "\n",
    "nn_gd = mlrose.NeuralNetwork(hidden_nodes = [100],\n",
    "                                activation = 'relu',\n",
    "                                algorithm = 'gradient_descent',\n",
    "                                max_iters = 100,\n",
    "                                bias = True,\n",
    "                                is_classifier = True,\n",
    "                                learning_rate = 0.001,\n",
    "                                early_stopping = True,\n",
    "                                clip_max = 5,\n",
    "                                max_attempts =100,\n",
    "                                curve=False,\n",
    "                                random_state = 123456)\n",
    "\n",
    "nn_ga = mlrose.NeuralNetwork(hidden_nodes = [100],\n",
    "                                activation = 'relu',\n",
    "                                algorithm = 'genetic_alg',\n",
    "                                max_iters = 100,\n",
    "                                bias = True,\n",
    "                                is_classifier = True,\n",
    "                                learning_rate = 0.001,\n",
    "                                early_stopping = True,\n",
    "                                clip_max = 5,\n",
    "                                max_attempts =100,\n",
    "                                curve=False,\n",
    "                                random_state = 123456)\n",
    "\n",
    "nn_sa = mlrose.NeuralNetwork(hidden_nodes = [100],\n",
    "                                activation = 'relu',\n",
    "                                algorithm = 'simulated_annealing',\n",
    "                                max_iters = 100,\n",
    "                                bias = True,\n",
    "                                is_classifier = True,\n",
    "                                learning_rate = 0.001,\n",
    "                                early_stopping = True,\n",
    "                                clip_max = 5,\n",
    "                                max_attempts =100,\n",
    "                                curve=False,\n",
    "                                random_state = 123456)\n",
    "\n",
    "nn_rhc = mlrose.NeuralNetwork(hidden_nodes = [100],\n",
    "                                activation = 'relu',\n",
    "                                algorithm = 'random_hill_climb',\n",
    "                                max_iters = 100,\n",
    "                                bias = True,\n",
    "                                is_classifier = True,\n",
    "                                learning_rate = 0.001,\n",
    "                                early_stopping = True,\n",
    "                                clip_max = 5,\n",
    "                                max_attempts =100,\n",
    "                                curve=False,\n",
    "                                random_state = 123456)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10), sharey=True)\n",
    "ax = ax.flatten()\n",
    "# fig.delaxes(ax[4])\n",
    "# fig.delaxes(ax[5])\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x_shroom,\n",
    "    \"y\": y_shroom,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=5, test_size=0.2, random_state=0),\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    # \"score_name\":make_scorer(accuracy_score),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "name_lst = ['gradient descent', 'randomized hill climb', 'genetic algorithm', 'simulated annealing']\n",
    "for ax_idx, estimator in enumerate([nn_gd, nn_rhc, nn_ga, nn_sa]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"{estimator.__class__.__name__} with {name_lst[ax_idx]}\", fontsize=15)\n",
    "    ax[ax_idx].set_xlabel('Number of samples in training set', fontsize='xx-large')\n",
    "    ax[ax_idx].set_ylabel('f1 score',fontsize = 15)\n",
    "    ax[ax_idx].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[ax_idx].tick_params(axis='both', which='minor', labelsize=15)\n",
    "fig.suptitle('Learning Curves for For Different Optimization Techniques', fontsize='xx-large')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes_ga, train_scores_ga, test_scores_ga, fit_times_ga, score_times_ga = learning_curve(\n",
    "    nn_sa, x_shroom, y_shroom, cv=5, n_jobs=-1, scoring='f1', train_sizes=np.linspace(0.05, 1.0, 10),\n",
    "      return_times=True, random_state=123456\n",
    ")\n",
    "\n",
    "train_sizes_ga, train_scores_ga, test_scores_ga, fit_times_ga, score_times_ga = learning_curve(\n",
    "    nn_ga, x_shroom, y_shroom, cv=5, n_jobs=-1, scoring='f1', train_sizes=np.linspace(0.05, 1.0, 10),\n",
    "      return_times=True, random_state=123456\n",
    ")\n",
    "\n",
    "train_sizes_rhc, train_scores_rhc, test_scores_rhc, fit_times_rhc, score_times_rhc = learning_curve(\n",
    "    nn_rhc, x_shroom, y_shroom, cv=5, n_jobs=-1, scoring='f1', train_sizes=np.linspace(0.05, 1.0, 10),\n",
    "      return_times=True, random_state=123456\n",
    ")\n",
    "\n",
    "train_sizes_gd, train_scores_gd, test_scores_gd, fit_times_gd, score_times_gd = learning_curve(\n",
    "    nn_gd, x_shroom, y_shroom, cv=5, n_jobs=-1, scoring='f1', train_sizes=np.linspace(0.05, 1.0, 10), return_times=True, random_state=123456\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_parameters = ({\n",
    "    \"activation\": [mlrose.neural.activation.relu],\n",
    "    \"is_classifier\": [True],\n",
    "    'max_iters': [100],                     # nn params\n",
    "    'learning_rate': [0.0001],                         # nn params\n",
    "    'schedule': [mlrose.ArithDecay(100)],  # sa params\n",
    "})\n",
    "\n",
    "nnr = NNGSRunner(x_train=x_shroom_train,\n",
    "                    y_train=y_shroom_train,\n",
    "                    x_test=x_shroom_test,\n",
    "                    y_test=y_shroom_test,\n",
    "                    experiment_name='nn_test',\n",
    "                    algorithm=mlrose.algorithms.sa.simulated_annealing,\n",
    "                    grid_search_parameters=grid_search_parameters,\n",
    "                    iteration_list=[100],\n",
    "                    hidden_layer_sizes=[[100]],\n",
    "                    bias=True,\n",
    "                    early_stopping=False,\n",
    "                    clip_max=1e+10,\n",
    "                    max_attempts=500,\n",
    "                    generate_curves=True,\n",
    "                    seed=123456)\n",
    "\n",
    "run_stats_df, curves_df, cv_results_df, sr = nnr.run()          # GridSearchCV instance returned   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_parameters = ({\n",
    "    \"activation\": [mlrose.neural.activation.relu],\n",
    "    \"is_classifier\": [True],\n",
    "    'max_iters': [150],                     # nn params\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],                         # nn params\n",
    "    'schedule': [mlrose.ArithDecay(20), mlrose.ArithDecay(40), mlrose.ArithDecay(60)]\n",
    "})\n",
    "\n",
    "nnr = NNGSRunner(x_train=x_shroom_train,\n",
    "                    y_train=y_shroom_train,\n",
    "                    x_test=x_shroom_test,\n",
    "                    y_test=y_shroom_test,\n",
    "                    experiment_name='nn_test',\n",
    "                    algorithm=mlrose.algorithms.sa.simulated_annealing,\n",
    "                    grid_search_parameters=grid_search_parameters,\n",
    "                    iteration_list=[100, 500, 1000],\n",
    "                    hidden_layer_sizes=[[10], [50], [100]],\n",
    "                    bias=True,\n",
    "                    early_stopping=False,\n",
    "                    clip_max=1e+10,\n",
    "                    max_attempts=500,\n",
    "                    generate_curves=True,\n",
    "                    seed=123456)\n",
    "\n",
    "run_stats_df, curves_df, cv_results_df, sr = nnr.run()          # GridSearchCV instance returned   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_parameters = ({\n",
    "    \"activation\": [mlrose.neural.activation.relu],\n",
    "    \"is_classifier\": [True],\n",
    "    'max_iters': [1],\n",
    "    'learning_rate': [0.0001],\n",
    "})\n",
    "\n",
    "nnr = NNGSRunner(x_train=x_shroom_train,\n",
    "                    y_train=y_shroom_train,\n",
    "                    x_test=x_shroom_test,\n",
    "                    y_test=y_shroom_test,\n",
    "                    experiment_name='nn_test',\n",
    "                    algorithm=mlrose.algorithms.ga.genetic_alg,\n",
    "                    grid_search_parameters=grid_search_parameters,\n",
    "                    iteration_list=[100],\n",
    "                    hidden_layer_sizes=[[100]],\n",
    "                    bias=True,\n",
    "                    early_stopping=False,\n",
    "                    clip_max=1e+10,\n",
    "                    max_attempts=500,\n",
    "                    generate_curves=True,\n",
    "                    seed=123456)\n",
    "\n",
    "run_stats_df, curves_df, cv_results_df, sr = nnr.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_parameters = ({\n",
    "    \"activation\": [mlrose.neural.activation.relu],\n",
    "    \"is_classifier\": [True],\n",
    "    'max_iters': [150],\n",
    "    'learning_rate': [0.0001],\n",
    "})\n",
    "\n",
    "nnr = NNGSRunner(x_train=x_shroom_train,\n",
    "                    y_train=y_shroom_train,\n",
    "                    x_test=x_shroom_test,\n",
    "                    y_test=y_shroom_test,\n",
    "                    experiment_name='nn_test',\n",
    "                    algorithm=mlrose.algorithms.rhc.random_hill_climb,\n",
    "                    grid_search_parameters=grid_search_parameters,\n",
    "                    iteration_list=[100],\n",
    "                    hidden_layer_sizes=[[100]],\n",
    "                    bias=True,\n",
    "                    early_stopping=False,\n",
    "                    clip_max=1e+10,\n",
    "                    max_attempts=500,\n",
    "                    generate_curves=True,\n",
    "                    seed=123456)\n",
    "\n",
    "run_stats_df, curves_df, cv_results_df, sr = nnr.run()          # GridSearchCV instance returned   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune max_iters and learning_rate_init\n",
    "grid_search = {\n",
    "    \"max_iters\": [5000, 10000, 25000, 50000],\n",
    "    \"learning_rate_init\": [0.001, 0.1, 0.1, 0.5, 1],\n",
    "    \"activation\": [mlrose.neural.activation.relu],\n",
    "    \"is_classifier\": [True],\n",
    "}\n",
    "\n",
    "runner = NNGSRunner(x_train=x_shroom_train,\n",
    "                    y_train=y_shroom_train,\n",
    "                    x_test=x_shroom_test,\n",
    "                    y_test=y_shroom_test,\n",
    "                    experiment_name=\"full_grid_search\",\n",
    "                    algorithm=mlrose.algorithms.gradient_descent,\n",
    "                    grid_search_parameters=grid_search,\n",
    "                    iteration_list = [1000, 2500, 5000, 10000],\n",
    "                    hidden_layer_sizes=[[6,6]],\n",
    "                    bias=True,\n",
    "                    early_stopping=True,\n",
    "                    clip_max=1,\n",
    "                    max_attempts=1000,\n",
    "                    generate_curves=True,\n",
    "                    seed=123456,\n",
    "                    n_jobs=-1\n",
    "                          )\n",
    "run_stats, curves, cv_results, best_est = runner.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Fitness Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Queens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = mlrose.Queens()\n",
    "four_fitness = mlrose.FourPeaks()\n",
    "weights = [10, 5, 2, 8, 15, 13, 18, 25]\n",
    "values = list(np.arange(1, 9))\n",
    "max_weight_pct = 0.5\n",
    "knap_fitness = mlrose.Knapsack(weights, values, max_weight_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = mlrose.DiscreteOpt(\n",
    "    length = 8, fitness_fn = fitness, \n",
    "    maximize = False, max_val = 8\n",
    "    )\n",
    "\n",
    "four_problem = mlrose.DiscreteOpt(\n",
    "    length = 8, fitness_fn = four_fitness, \n",
    "    maximize = False, max_val = 2\n",
    "    )\n",
    "\n",
    "knap_problem = mlrose.DiscreteOpt(\n",
    "    length = 8, fitness_fn = knap_fitness, \n",
    "    maximize = False, max_val = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = [10, 5, 2, 8, 15]\n",
    "values = [1, 2, 3, 4, 5]\n",
    "max_weight_pct = 0.6\n",
    "fitness = mlrose.Knapsack(weights, values, max_weight_pct)\n",
    "state = np.array([1, 0, 2, 1, 0])\n",
    "fitness.evaluate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to run an N-queens problem using\n",
    "# define a fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decay schedule\n",
    "schedule = mlrose.ExpDecay()\n",
    "\n",
    "# Define initial state\n",
    "init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Solve problem using simulated annealing\n",
    "best_state, best_fitness, curve = mlrose.simulated_annealing(\n",
    "    four_problem, schedule = schedule,\n",
    "    max_attempts = 10, max_iters = 1000,\n",
    "    init_state = init_state, random_state = 123321,\n",
    "    curve=True\n",
    "    )\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(curve[:,1], curve[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve problem using MIMIC\n",
    "best_state, best_fitness, curve = mlrose.mimic(\n",
    "    four_problem, max_attempts = 10, max_iters = 1000,\n",
    "    random_state = 123321, curve=True\n",
    "    )\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(curve[:,1], curve[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "sa_run = SARunner(problem=four_problem,\n",
    "              experiment_name='queens8_sa',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              max_attempts=500,\n",
    "              temperature_list=[0.1, 0.5, 0.75, 1.0, 2.0, 5.0],\n",
    "              decay_list=[mlrose.GeomDecay])\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = sa_run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "mimic_run = MIMICRunner(problem=problem,\n",
    "              experiment_name='queens8_sa',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              max_attempts=500,\n",
    "              population_sizes = [200],\n",
    "              keep_percent_list = [0.25, 0.5, 0.75]\n",
    "              )\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = mimic_run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_run.runner_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "ga_run = GARunner(problem=problem,\n",
    "              experiment_name='queens8_sa',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              max_attempts=500,\n",
    "              population_sizes = [200],\n",
    "              mutation_rates = [0.25, 0.5, 0.75]\n",
    "              )\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = ga_run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "rhc_run = RHCRunner(problem=problem,\n",
    "              experiment_name='queens8_sa',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              max_attempts=500,\n",
    "              restart_list=[25, 75, 100]\n",
    "              )\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = rhc_run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run_curves[(df_run_curves['Fitness']==0) & (df_run_curves['Iteration']<20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial state\n",
    "init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Solve problem using simulated annealing\n",
    "best_state, best_fitness, curve = mlrose.random_hill_climb(\n",
    "    problem, max_attempts = 10, max_iters = 1000,\n",
    "    init_state = init_state, random_state = 123321,\n",
    "    curve=True\n",
    "    )\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(curve[:,1], curve[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial state\n",
    "init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Solve problem using genetic algorithms\n",
    "best_state, best_fitness, curve = mlrose.genetic_alg(\n",
    "    problem, pop_size=200, mutation_prob=0.1, max_attempts=10, \n",
    "    max_iters=1000, curve=True, random_state=123321\n",
    "    )\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(curve[:,1], curve[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial state\n",
    "init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Solve problem using MIMIC\n",
    "best_state, best_fitness, curve = mlrose.mimic(\n",
    "    problem, pop_size=50, keep_pct=0.01, max_attempts=10,\n",
    "    max_iters=100, curve=True, random_state=123321\n",
    "    )\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(curve[:,1], curve[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = mlrose.NeuralNetwork(hidden_nodes = [], activation = 'sigmoid', \n",
    "                                    algorithm = 'random_hill_climb', \n",
    "                                    max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                    learning_rate = 0.01, early_stopping = True, \n",
    "                                    clip_max = 5, max_attempts = 100, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = {\n",
    "    'activation': 'relu', 'hidden_layer_sizes': (100,), \n",
    "    'learning_rate': 'constant', 'learning_rate_init': 0.01, \n",
    "    'solver': 'sgd'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
